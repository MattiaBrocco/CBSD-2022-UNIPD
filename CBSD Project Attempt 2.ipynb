{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1760d7bb",
   "metadata": {},
   "source": [
    "# Cognitive, behavioral and social data\n",
    "**DATASET**: PCL5  \n",
    "**Author**: Mattia Brocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32a4da",
   "metadata": {},
   "source": [
    "MERGE OF DATASETS FOR **R_NEO_PI**\n",
    "```python\n",
    "a = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Faked.xlsx\")\n",
    "b = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Honest.xlsx\")\n",
    "\n",
    "a.columns = [\" \".join([pd.Series(a.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       a.loc[0][i]]) for i in range(len(a.columns))]\n",
    "b.columns = [\" \".join([pd.Series(b.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       b.loc[0][i]]) for i in range(len(b.columns))]\n",
    "\n",
    "a = a.drop(0).reset_index(drop = True)\n",
    "b = b.drop(0).reset_index(drop = True)\n",
    "\n",
    "a[\"CONDITION\"] = \"FAKE\"\n",
    "b[\"CONDITION\"] = \"HONEST\"\n",
    "\n",
    "pd.concat([a, b], ignore_index = True).to_excel(data_dir + \"\\\\R_NEO_PI.xlsx\", index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc59e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:09:16.442096Z",
     "start_time": "2022-11-11T14:09:01.146215Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import support\n",
    "from enginev2 import Classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = \".\\\\data\"\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9149499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:09:16.688722Z",
     "start_time": "2022-11-11T14:09:16.444121Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae53c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:09:47.584174Z",
     "start_time": "2022-11-11T14:09:16.692710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF_df_CTU\n",
      "BF_df_OU\n",
      "BF_df_V\n",
      "DT_df_CC\n",
      "DT_df_JI\n",
      "IADQ_df\n",
      "IESR_df\n",
      "NAQ_R_df\n",
      "PCL5_df\n",
      "PHQ9_GAD7_df\n",
      "PID5_df\n",
      "PRFQ_df\n",
      "PRMQ_df\n",
      "RAW_DDDT\n",
      "R_NEO_PI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeather\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f]:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m     a, b, c, d \u001b[38;5;241m=\u001b[39m \u001b[43mClassification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCONDITION\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     data_collection[dataset\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [a, b, c, d]\n",
      "File \u001b[1;32m~\\OneDrive\\Data Science Year 2\\1M. Cognitive Behavioral & Social data\\3. Project\\CBSD-2022-UNIPD\\enginev2.py:70\u001b[0m, in \u001b[0;36mClassification.prepare_data\u001b[1;34m(self, data_dir, target)\u001b[0m\n\u001b[0;32m     68\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(target, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\n\u001b[1;32m---> 70\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     72\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.7\u001b[39m,\n\u001b[0;32m     73\u001b[0m                                                     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Scale data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Data Science Year 2\\1M. Cognitive Behavioral & Social data\\3. Project\\CBSD-2022-UNIPD\\enginev2.py:70\u001b[0m, in \u001b[0;36mClassification.prepare_data.<locals>.<lambda>\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m     68\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(target, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     69\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\n\u001b[1;32m---> 70\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m     72\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.7\u001b[39m,\n\u001b[0;32m     73\u001b[0m                                                     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Scale data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:2088\u001b[0m, in \u001b[0;36mSeries.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   2031\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[0;32m   2033\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:989\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    987\u001b[0m             result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result)\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:440\u001b[0m, in \u001b[0;36munique\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    437\u001b[0m htable, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    439\u001b[0m table \u001b[38;5;241m=\u001b[39m htable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 440\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Organize datasets\n",
    "data_collection = {}\n",
    "for dataset in [f for f in os.listdir(data_dir) if \"feather\" in f]:\n",
    "    print(dataset.split(\".\")[0])\n",
    "    \n",
    "    a, b, c, d = Classification().prepare_data(f\"{data_dir}\\\\{dataset}\", \"CONDITION\")\n",
    "    \n",
    "    data_collection[dataset.split(\".\")[0]] = [a, b, c, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64bf812c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T14:09:49.907394Z",
     "start_time": "2022-11-11T14:09:49.632380Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_collection[\"BF_df_CTU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81669b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T07:54:36.259182Z",
     "start_time": "2022-11-10T07:54:36.023266Z"
    }
   },
   "outputs": [],
   "source": [
    "#a = pd.DataFrame(np.c_[new_X_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd8dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:55:59.564255Z",
     "start_time": "2022-11-10T08:55:59.079007Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pruned_tree = support.D3_pruning(new_X_train, y_train)\n",
    "\n",
    "random_forest = GradientBoostingClassifier(random_state = 42,\n",
    "                                           ccp_alpha = pruned_tree.best_params_[\"ccp_alpha\"])\n",
    "random_forest.fit(new_X_train, y_train)\n",
    "\n",
    "# 1.3 Feature selection\n",
    "perm_imp = permutation_importance(random_forest, pca2.transform(X_test),\n",
    "                                  y_test, n_repeats = 30,\n",
    "                                  random_state = 42, scoring = \"accuracy\",\n",
    "                                  n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccf2da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:57:25.123090Z",
     "start_time": "2022-11-10T08:57:24.780157Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(perm_imp[\"importances\"]).T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c9804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:59:22.881090Z",
     "start_time": "2022-11-10T08:59:22.581675Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(random_state = 42, n_jobs = -1)\n",
    "logit.fit(new_X_train[:, 0].reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40db029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:00:21.029613Z",
     "start_time": "2022-11-10T09:00:20.792634Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, logit.predict(pca2.transform(X_test)[:, 0].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab897b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:16:50.421042Z",
     "start_time": "2022-11-10T09:16:50.185709Z"
    }
   },
   "outputs": [],
   "source": [
    "covariance_mat = np.cov(X_train, rowvar = False)\n",
    "    \n",
    "eigenvalues, eigenvectors = np.linalg.eig(covariance_mat)\n",
    "sorted_indeces = np.flip(np.argsort(eigenvalues))\n",
    "P = eigenvectors[:, sorted_indeces]\n",
    "W = P[:, 0:3]\n",
    "Y_hat = np.dot(X_train, W)\n",
    "W_hat = W.T\n",
    "X_hat = np.dot(Y_hat, W_hat)\n",
    "    \n",
    "#approx_data = scaler.inverse_transform(X_hat)\n",
    "#ecg_sig_rec = matrix_to_signal(approx_data, original_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c538ac6",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/50796024/feature-variable-importance-after-a-pca-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a9bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:20:14.109268Z",
     "start_time": "2022-11-10T09:20:13.736682Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 6))\n",
    "sns.heatmap(np.power(pca2.inverse_transform(new_X_train) - X_train, 2), yticklabels = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe875cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:16:23.591952Z",
     "start_time": "2022-11-10T09:16:23.356546Z"
    }
   },
   "outputs": [],
   "source": [
    "new_X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497585ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e054424",
   "metadata": {},
   "outputs": [],
   "source": [
    "(309 x 10)*(10 x 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68622351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:08:06.817092Z",
     "start_time": "2022-11-10T09:08:06.578521Z"
    }
   },
   "outputs": [],
   "source": [
    "np.dot(pca2.components_, X_train.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa734a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T09:05:09.860052Z",
     "start_time": "2022-11-10T09:05:09.612745Z"
    }
   },
   "outputs": [],
   "source": [
    "new_X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43866185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4706e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e862db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c8c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:40:54.005909Z",
     "start_time": "2022-11-10T08:40:53.551221Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "PartialDependenceDisplay.from_estimator(random_forest, new_X_train, [0, 1, 2],\n",
    "                                        kind = \"average\", method = \"recursion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eec411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:44:11.539037Z",
     "start_time": "2022-11-10T08:44:11.206462Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(new_X_train[:,0].min(), new_X_train[:,0].max(), num = len(prova[\"values\"][0])), prova[\"values\"][0])\n",
    "plt.plot(np.linspace(new_X_train[:,0].min(), new_X_train[:,0].max(), num = len(prova[\"values\"][0])), prova[\"values\"][1])\n",
    "plt.plot(np.linspace(new_X_train[:,0].min(), new_X_train[:,0].max(), num = len(prova[\"values\"][0])), prova[\"values\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3e921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T08:37:48.833184Z",
     "start_time": "2022-11-10T08:37:48.347248Z"
    }
   },
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(pruned_tree.best_estimator_, new_X_train, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90227011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
