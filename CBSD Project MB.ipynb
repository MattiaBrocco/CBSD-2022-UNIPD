{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65e68df",
   "metadata": {},
   "source": [
    "# Cognitive, behavioral and social data\n",
    "**DATASET**: PCL5  \n",
    "**Author**: Mattia Brocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adef96",
   "metadata": {},
   "source": [
    "MERGE OF DATASETS FOR **R_NEO_PI**\n",
    "```python\n",
    "a = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Faked.xlsx\")\n",
    "b = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Honest.xlsx\")\n",
    "\n",
    "a.columns = [\" \".join([pd.Series(a.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       a.loc[0][i]]) for i in range(len(a.columns))]\n",
    "b.columns = [\" \".join([pd.Series(b.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       b.loc[0][i]]) for i in range(len(b.columns))]\n",
    "\n",
    "a = a.drop(0).reset_index(drop = True)\n",
    "b = b.drop(0).reset_index(drop = True)\n",
    "\n",
    "a[\"CONDITION\"] = \"FAKE\"\n",
    "b[\"CONDITION\"] = \"HONEST\"\n",
    "\n",
    "pd.concat([a, b], ignore_index = True).to_excel(data_dir + \"\\\\R_NEO_PI.xlsx\", index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6cda3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T14:52:52.401748Z",
     "start_time": "2022-11-07T14:52:27.051307Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import support\n",
    "from engine import Classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = \".\\\\data\"\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b91d4e",
   "metadata": {},
   "source": [
    "---\n",
    "## Try to design a pipeline\n",
    "***\n",
    "\n",
    "SOURCES  \n",
    "* [Factor Analysis](https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/factor-analysis/)\n",
    "* [Likelihood-ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test)\n",
    "* [How can I get statistics to compare nested models in a logistic regression in SPSS?](https://www.ibm.com/support/pages/how-can-i-get-statistics-compare-nested-models-logistic-regression-spss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23cb893e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T23:31:21.603172Z",
     "start_time": "2022-11-03T23:13:26.183266Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF_df_CTU\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Sample size: 309\n",
      "Selected 2 features out of 10\n",
      "{'Features': [6, 4], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.789474\n",
      "Logistic Regression    0.781955\n",
      "SVC                    0.827068\n",
      "Random Forest          0.827068\n",
      "Neural Network         0.781955\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "BF_df_OU\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Sample size: 322\n",
      "Selected 2 features out of 10\n",
      "{'Features': [6, 4], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.840580\n",
      "Logistic Regression    0.782609\n",
      "SVC                    0.804348\n",
      "Random Forest          0.804348\n",
      "Neural Network         0.760870\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "BF_df_V\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Sample size: 340\n",
      "Selected 2 features out of 10\n",
      "{'Features': [4, 7], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.753425\n",
      "Logistic Regression    0.719178\n",
      "SVC                    0.719178\n",
      "Random Forest          0.726027\n",
      "Neural Network         0.691781\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "DT_df_CC\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Sample size: 337\n",
      "Selected 4 features out of 27\n",
      "{'Features': [13, 9, 8, 16], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.696552\n",
      "Logistic Regression    0.710345\n",
      "SVC                    0.655172\n",
      "Random Forest          0.648276\n",
      "Neural Network         0.703448\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "DT_df_JI\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Sample size: 604\n",
      "Selected 5 features out of 27\n",
      "{'Features': [2, 3, 15, 18, 24], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.650000\n",
      "Logistic Regression    0.607692\n",
      "SVC                    0.592308\n",
      "Random Forest          0.553846\n",
      "Neural Network         0.588462\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "IADQ_df\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Sample size: 315\n",
      "Selected 3 features out of 9\n",
      "{'Features': [1, 4, 6], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.851852\n",
      "Logistic Regression    0.844444\n",
      "SVC                    0.837037\n",
      "Random Forest          0.837037\n",
      "Neural Network         0.770370\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "IESR_df\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Sample size: 250\n",
      "Selected 3 features out of 22\n",
      "{'Features': [13, 18, 19], 'Wilks test p-value': 1.0, 'Validation passed': True}\n",
      "Full Logit             0.944444\n",
      "Logistic Regression    0.898148\n",
      "SVC                    0.898148\n",
      "Random Forest          0.879630\n",
      "Neural Network         0.916667\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "NAQ_R_df\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Sample size: 498\n",
      "Selected 2 features out of 22\n",
      "{'Features': [1, 9], 'Wilks test p-value': 1.0, 'Validation passed': True}\n",
      "Full Logit             0.971963\n",
      "Logistic Regression    0.971963\n",
      "SVC                    0.971963\n",
      "Random Forest          0.971963\n",
      "Neural Network         0.971963\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PCL5_df\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Sample size: 281\n",
      "Selected 2 features out of 20\n",
      "{'Features': [1, 4], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.834711\n",
      "Logistic Regression    0.826446\n",
      "SVC                    0.818182\n",
      "Random Forest          0.826446\n",
      "Neural Network         0.826446\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PHQ9_GAD7_df\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "Sample size: 782\n",
      "Selected 3 features out of 16\n",
      "{'Features': [7, 1, 6], 'Wilks test p-value': 1.0, 'Validation passed': True}\n",
      "Full Logit             0.988095\n",
      "Logistic Regression    0.982143\n",
      "SVC                    0.982143\n",
      "Random Forest          0.967262\n",
      "Neural Network         0.973214\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PID5_df\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "Sample size: 576\n",
      "Selected 1 features out of 220\n",
      "{'Features': [1], 'Wilks test p-value': 1.0, 'Validation passed': True}\n",
      "Full Logit             0.967742\n",
      "Logistic Regression    0.891129\n",
      "SVC                    0.891129\n",
      "Random Forest          0.891129\n",
      "Neural Network         0.891129\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PRFQ_df\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Sample size: 474\n",
      "Selected 4 features out of 18\n",
      "{'Features': [2, 6, 8, 11], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.926471\n",
      "Logistic Regression    0.901961\n",
      "SVC                    0.926471\n",
      "Random Forest          0.911765\n",
      "Neural Network         0.911765\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PRMQ_df\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "Sample size: 982\n",
      "Selected 6 features out of 16\n",
      "{'Features': [1, 7, 12, 4, 11, 2], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.907583\n",
      "Logistic Regression    0.890995\n",
      "SVC                    0.902844\n",
      "Random Forest          0.895735\n",
      "Neural Network         0.890995\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "RAW_DDDT\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Sample size: 690\n",
      "Selected 4 features out of 12\n",
      "{'Features': [0, 10, 7, 2], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.739865\n",
      "Logistic Regression    0.739865\n",
      "SVC                    0.750000\n",
      "Random Forest          0.750000\n",
      "Neural Network         0.743243\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "R_NEO_PI\n",
      "729/729 [==============================] - 1s 889us/step\n",
      "Sample size: 54380\n",
      "Selected 11 features out of 30\n",
      "{'Features': [29, 21, 13, 10, 5, 22, 1, 11, 8, 6, 26], 'Wilks test p-value': 1.0, 'Validation passed': False}\n",
      "Full Logit             0.906723\n",
      "Logistic Regression    0.905908\n",
      "SVC                    0.912558\n",
      "Random Forest          0.912215\n",
      "Neural Network         0.905994\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "sPID-5_df\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Sample size: 726\n",
      "Selected 4 features out of 25\n",
      "{'Features': [23, 4, 11, 16], 'Wilks test p-value': 1.0, 'Validation passed': True}\n",
      "Full Logit             0.974359\n",
      "Logistic Regression    0.958333\n",
      "SVC                    0.958333\n",
      "Random Forest          0.948718\n",
      "Neural Network         0.958333\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### PIPELINE\n",
    "# Organize datasets\n",
    "data_collection = {}\n",
    "for dataset in [f for f in os.listdir(data_dir) if \"feather\" in f]:\n",
    "    print(dataset.split(\".\")[0])\n",
    "    a, b, c, d = Classification().prepare_data(f\"{data_dir}\\\\{dataset}\", \"CONDITION\")\n",
    "    e = Classification().variable_selection(a, b, c, d)\n",
    "    f = Classification().benchmark_models(a, b, c, d, e)\n",
    "    data_collection[dataset.split(\".\")[0]] = [a, b, c, d, e, f]\n",
    "    print(e)\n",
    "    print(f)\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d5845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e56f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T14:54:21.364370Z",
     "start_time": "2022-11-07T14:53:35.997171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "Sample size: 576\n",
      "Selected 1 features out of 220\n"
     ]
    }
   ],
   "source": [
    "a, b, c, d = Classification().prepare_data(\".\\\\data\\\\PID5_df.feather\", \"CONDITION\")\n",
    "e = Classification().variable_selection(a, b, c, d)\n",
    "f = Classification().benchmark_models(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b3d10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T14:55:36.993373Z",
     "start_time": "2022-11-07T14:55:36.405436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Features': [1], 'Wilks test p-value': 1.0, 'Validation passed': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69774ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2f752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8164c4b",
   "metadata": {},
   "source": [
    "## Instead, use a paper from literature\n",
    "SOURCES\n",
    "* [Model-agnostic Feature Importance and Effects with Dependent Features -- A Conditional Subgroup Approach](https://arxiv.org/abs/2006.04628)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba82ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T10:18:57.376138Z",
     "start_time": "2022-11-03T10:18:57.113620Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06818a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T10:21:43.127619Z",
     "start_time": "2022-11-03T10:21:37.357050Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = engine.Classification().prepare_data(f\"{data_dir}\\\\BF_df_CTU.csv\", \"CONDITION\")\n",
    "\n",
    "lr = LogisticRegression(n_jobs = -1, random_state = 42, max_iter = 5e3)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6e781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T10:21:45.637275Z",
     "start_time": "2022-11-03T10:21:45.301006Z"
    }
   },
   "outputs": [],
   "source": [
    "pi = permutation_importance(lr, X_test, y_test, n_repeats = 30,\n",
    "                            random_state = 42, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbacd2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T10:24:41.491582Z",
     "start_time": "2022-11-03T10:24:41.132453Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(pi[\"importances_mean\"])), height = pi[\"importances_mean\"])\n",
    "plt.scatter(range(len(pi[\"importances_mean\"])),\n",
    "            pi[\"importances_mean\"] + pi[\"importances_std\"], color = \"orange\")\n",
    "plt.scatter(range(len(pi[\"importances_mean\"])),\n",
    "            pi[\"importances_mean\"] - pi[\"importances_std\"], color = \"orange\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
