{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65e68df",
   "metadata": {},
   "source": [
    "# Cognitive, behavioral and social data\n",
    "**DATASET**: PCL5  \n",
    "**Author**: Mattia Brocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adef96",
   "metadata": {},
   "source": [
    "MERGE OF DATASETS FOR **R_NEO_PI**\n",
    "```python\n",
    "a = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Faked.xlsx\")\n",
    "b = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Honest.xlsx\")\n",
    "\n",
    "a.columns = [\" \".join([pd.Series(a.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       a.loc[0][i]]) for i in range(len(a.columns))]\n",
    "b.columns = [\" \".join([pd.Series(b.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       b.loc[0][i]]) for i in range(len(b.columns))]\n",
    "\n",
    "a = a.drop(0).reset_index(drop = True)\n",
    "b = b.drop(0).reset_index(drop = True)\n",
    "\n",
    "a[\"CONDITION\"] = \"FAKE\"\n",
    "b[\"CONDITION\"] = \"HONEST\"\n",
    "\n",
    "pd.concat([a, b], ignore_index = True).to_excel(data_dir + \"\\\\R_NEO_PI.xlsx\", index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6cda3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T18:30:28.179838Z",
     "start_time": "2022-11-11T18:30:15.923683Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import support\n",
    "from engine import Classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = \".\\\\data\"\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb0745",
   "metadata": {},
   "source": [
    "### Datasets at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b0038cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T20:59:46.024028Z",
     "start_time": "2022-11-11T20:59:45.536580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BF_df_CTU.feather</td>\n",
       "      <td>442</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BF_df_OU.feather</td>\n",
       "      <td>460</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BF_df_V.feather</td>\n",
       "      <td>486</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_df_CC.feather</td>\n",
       "      <td>482</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT_df_JI.feather</td>\n",
       "      <td>864</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IADQ_df.feather</td>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IESR_df.feather</td>\n",
       "      <td>358</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAQ_R_df.feather</td>\n",
       "      <td>712</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCL5_df.feather</td>\n",
       "      <td>402</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PHQ9_GAD7_df.feather</td>\n",
       "      <td>1118</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PID5_df.feather</td>\n",
       "      <td>824</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRFQ_df.feather</td>\n",
       "      <td>678</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRMQ_df.feather</td>\n",
       "      <td>1404</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RAW_DDDT.feather</td>\n",
       "      <td>986</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R_NEO_PI.feather</td>\n",
       "      <td>77687</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sPID-5_df.feather</td>\n",
       "      <td>1038</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Data  Sample size  Features\n",
       "0      BF_df_CTU.feather          442        11\n",
       "1       BF_df_OU.feather          460        11\n",
       "2        BF_df_V.feather          486        11\n",
       "3       DT_df_CC.feather          482        28\n",
       "4       DT_df_JI.feather          864        28\n",
       "5        IADQ_df.feather          450        10\n",
       "6        IESR_df.feather          358        23\n",
       "7       NAQ_R_df.feather          712        23\n",
       "8        PCL5_df.feather          402        21\n",
       "9   PHQ9_GAD7_df.feather         1118        17\n",
       "10       PID5_df.feather          824       221\n",
       "11       PRFQ_df.feather          678        19\n",
       "12       PRMQ_df.feather         1404        17\n",
       "13      RAW_DDDT.feather          986        13\n",
       "14      R_NEO_PI.feather        77687        31\n",
       "15     sPID-5_df.feather         1038        26"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_descr = pd.DataFrame(dict(zip([f for f in os.listdir(data_dir) if \"feather\" in f],\n",
    "                                   [pd.read_feather(f\"{data_dir}\\\\{f}\").shape for f in os.listdir(data_dir)\n",
    "                                    if \"feather\" in f]))).T.reset_index()\n",
    "data_descr = data_descr.rename(columns = {\"index\": \"Data\", 0: \"Sample size\",\n",
    "                                          1: \"Features\"})\n",
    "data_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f32564",
   "metadata": {},
   "source": [
    "---\n",
    "## Design a pipeline\n",
    "***\n",
    "\n",
    "The goal is to find a stable subset of features across datasets that performs roughly the same across different classifiers. Accoringly, we can define a \"good\" feature selection procedure, one that does not depend on a specific model, but that allows models to perform roughly the same, and for all the datasets within the scope.\n",
    "\n",
    "##### DESCRIPTION\n",
    "1. A given dataset is split in training and test. For every feature, the mean and the standard deviation are computed in order to scale that feauture: $Z=\\frac{X-\\mu}{\\sigma}$. Scaling on the test set is carried out using the same values computed for training data.\n",
    "2. The actual phase of the selection of a subset of features occurs through a 3-step process:  \n",
    "    * Train a Decision Tree and apply minimal cost-complexity pruning. <sup>[1]</sup>  \n",
    "    * Train a Random Forest that expolits gradient boosting <sup>[2]</sup>, in which each tree retains the cost-complexity parameter obtained in the previous step.  \n",
    "    * Compute permutation importance on this Random Forest <sup>[3]</sup>.  \n",
    "    * Perform a one-sample test on the mean, given the distribution obtained for each feature importance (with confidence level at 99.999%). This way only features whose importance is significantly greater than zero are retained, all the others are discarded. We call this subset of feature $A^*$  \n",
    "    * Perform a Wilks test <sup>[4]</sup> comparing two logistic regressions, one fitted with the full set of features, the other with $A^*$. By accepting the null hypothesis of the test (at 95% confidence level), the assertion \"the ration  between the likelihoods of the two (nested) models is one\".  \n",
    "    * Train an arbitrary amount of different models in order to assess the quality of the feature selection procedure. If all models show very close accuracy, then the procedure proves to provide a model-indifferent subset $A^*$ of features.\n",
    "\n",
    "\n",
    "##### SOURCES\n",
    "* [How can I get statistics to compare nested models in a logistic regression in SPSS?](https://www.ibm.com/support/pages/how-can-i-get-statistics-compare-nested-models-logistic-regression-spss)\n",
    "* [Likelihood-ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test)\n",
    "\n",
    "##### SUPPORTING PAPERS\n",
    "[1] L. Breiman, J. Friedman, R. Olshen, and C. Stone. *Classification and Regression Trees*. Wadsworth, Belmont, CA, 1984.  \n",
    "[2] J. Friedman, Greedy Function Approximation: *A Gradient Boosting Machine*, The Annals of Statistics, Vol. 29, No. 5, 2001  \n",
    "[3] Leo Breiman. Random forests. *Machine learning*, 45(1):5-32, 2001.  \n",
    "[4] Li, Bing; Babu, G. Jogesh (2019). *A Graduate Course on Statistical Inference*. Springer. p. 331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23cb893e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T19:09:25.019714Z",
     "start_time": "2022-11-11T18:57:40.028357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF_df_CTU\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train size: 309\n",
      "Selected 4 features out of 10\n",
      "{'Features': [2, 4, 6, 7], 'Wilks test p-value': 0.9893064, 'High correlation': False}\n",
      "Full Logit             0.774436\n",
      "Logistic Regression    0.812030\n",
      "SVC                    0.842105\n",
      "Random Forest          0.827068\n",
      "Neural Network         0.812030\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "BF_df_OU\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train size: 322\n",
      "Selected 4 features out of 10\n",
      "{'Features': [0, 4, 6, 7], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.833333\n",
      "Logistic Regression    0.797101\n",
      "SVC                    0.847826\n",
      "Random Forest          0.840580\n",
      "Neural Network         0.833333\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "BF_df_V\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "Train size: 340\n",
      "Selected 2 features out of 10\n",
      "{'Features': [4, 7], 'Wilks test p-value': 0.9997179, 'High correlation': False}\n",
      "Full Logit             0.760274\n",
      "Logistic Regression    0.719178\n",
      "SVC                    0.719178\n",
      "Random Forest          0.726027\n",
      "Neural Network         0.719178\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "DT_df_CC\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train size: 337\n",
      "Selected 5 features out of 27\n",
      "{'Features': [8, 9, 10, 13, 16], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.682759\n",
      "Logistic Regression    0.717241\n",
      "SVC                    0.717241\n",
      "Random Forest          0.731034\n",
      "Neural Network         0.703448\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "DT_df_JI\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Train size: 604\n",
      "Selected 4 features out of 27\n",
      "{'Features': [2, 15, 17, 18], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.661538\n",
      "Logistic Regression    0.646154\n",
      "SVC                    0.584615\n",
      "Random Forest          0.592308\n",
      "Neural Network         0.638462\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "IADQ_df\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Train size: 315\n",
      "Selected 3 features out of 9\n",
      "{'Features': [1, 4, 6], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.851852\n",
      "Logistic Regression    0.851852\n",
      "SVC                    0.837037\n",
      "Random Forest          0.837037\n",
      "Neural Network         0.844444\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "IESR_df\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Train size: 250\n",
      "Selected 4 features out of 22\n",
      "{'Features': [8, 13, 18, 19], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "Full Logit             0.935185\n",
      "Logistic Regression    0.888889\n",
      "SVC                    0.925926\n",
      "Random Forest          0.907407\n",
      "Neural Network         0.925926\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "NAQ_R_df\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Train size: 498\n",
      "Selected 6 features out of 22\n",
      "{'Features': [1, 6, 9, 12, 16, 21], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "Full Logit             0.953271\n",
      "Logistic Regression    0.967290\n",
      "SVC                    0.976636\n",
      "Random Forest          0.971963\n",
      "Neural Network         0.976636\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PCL5_df\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Train size: 281\n",
      "Selected 2 features out of 20\n",
      "{'Features': [1, 4], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.809917\n",
      "Logistic Regression    0.826446\n",
      "SVC                    0.826446\n",
      "Random Forest          0.818182\n",
      "Neural Network         0.826446\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PHQ9_GAD7_df\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Train size: 782\n",
      "Selected 3 features out of 16\n",
      "{'Features': [1, 6, 7], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "Full Logit             0.991071\n",
      "Logistic Regression    0.979167\n",
      "SVC                    0.982143\n",
      "Random Forest          0.976190\n",
      "Neural Network         0.979167\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PID5_df\n",
      "8/8 [==============================] - 0s 994us/step\n",
      "Train size: 576\n",
      "Selected 1 features out of 220\n",
      "{'Features': [1], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "Full Logit             0.959677\n",
      "Logistic Regression    0.891129\n",
      "SVC                    0.891129\n",
      "Random Forest          0.891129\n",
      "Neural Network         0.891129\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PRFQ_df\n",
      "7/7 [==============================] - 0s 990us/step\n",
      "Train size: 474\n",
      "Selected 5 features out of 18\n",
      "{'Features': [2, 6, 8, 11, 15], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.936275\n",
      "Logistic Regression    0.931373\n",
      "SVC                    0.931373\n",
      "Random Forest          0.921569\n",
      "Neural Network         0.931373\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "PRMQ_df\n",
      "14/14 [==============================] - 0s 1000us/step\n",
      "Train size: 982\n",
      "Selected 6 features out of 16\n",
      "{'Features': [1, 2, 4, 7, 11, 12], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.907583\n",
      "Logistic Regression    0.888626\n",
      "SVC                    0.909953\n",
      "Random Forest          0.890995\n",
      "Neural Network         0.890995\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "RAW_DDDT\n",
      "10/10 [==============================] - 0s 997us/step\n",
      "Train size: 690\n",
      "Selected 6 features out of 12\n",
      "{'Features': [0, 1, 2, 7, 9, 10], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.746622\n",
      "Logistic Regression    0.743243\n",
      "SVC                    0.756757\n",
      "Random Forest          0.756757\n",
      "Neural Network         0.756757\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "R_NEO_PI\n",
      "729/729 [==============================] - 1s 771us/step\n",
      "Train size: 54380\n",
      "Selected 18 features out of 30\n",
      "{'Features': [1, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 18, 20, 21, 22, 26, 27, 29], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "Full Logit             0.906938\n",
      "Logistic Regression    0.907067\n",
      "SVC                    0.915004\n",
      "Random Forest          0.911872\n",
      "Neural Network         0.913417\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n",
      "sPID-5_df\n",
      "10/10 [==============================] - 0s 890us/step\n",
      "Train size: 726\n",
      "Selected 6 features out of 25\n",
      "{'Features': [2, 4, 11, 16, 20, 23], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "Full Logit             0.961538\n",
      "Logistic Regression    0.967949\n",
      "SVC                    0.967949\n",
      "Random Forest          0.964744\n",
      "Neural Network         0.961538\n",
      "dtype: float64\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### PIPELINE\n",
    "# Organize datasets\n",
    "data_collection = {}\n",
    "for dataset in [f for f in os.listdir(data_dir) if \"feather\" in f]:\n",
    "    print(dataset.split(\".\")[0])\n",
    "    a, b, c, d = Classification().prepare_data(f\"{data_dir}\\\\{dataset}\", \"CONDITION\")\n",
    "    e = Classification().variable_selection(a, b, c, d)\n",
    "    f = Classification().benchmark_models(a, b, c, d, e)\n",
    "    data_collection[dataset.split(\".\")[0]] = [a, b, c, d, e, f]\n",
    "    print(e)\n",
    "    print(f)\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1745d9a",
   "metadata": {},
   "source": [
    "## Summarize results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bac3cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-11T21:12:03.268067Z",
     "start_time": "2022-11-11T21:12:03.036943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Training size</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Selected Features</th>\n",
       "      <th>ACCURACY - Logit with all features</th>\n",
       "      <th>ACCURACY - Logistic Regression</th>\n",
       "      <th>ACCURACY - SVM</th>\n",
       "      <th>ACCURACY - Random Forest</th>\n",
       "      <th>ACCURACY - Neural Network</th>\n",
       "      <th>Average Accuracy on selected features</th>\n",
       "      <th>Accuracy std on selected features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BF_df_CTU</td>\n",
       "      <td>442</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774436</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.823308</td>\n",
       "      <td>0.014397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BF_df_OU</td>\n",
       "      <td>460</td>\n",
       "      <td>322</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.829710</td>\n",
       "      <td>0.022530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BF_df_V</td>\n",
       "      <td>486</td>\n",
       "      <td>340</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.720890</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_df_CC</td>\n",
       "      <td>482</td>\n",
       "      <td>337</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.717241</td>\n",
       "      <td>0.011262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT_df_JI</td>\n",
       "      <td>864</td>\n",
       "      <td>604</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.638462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.031404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IADQ_df</td>\n",
       "      <td>450</td>\n",
       "      <td>315</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IESR_df</td>\n",
       "      <td>358</td>\n",
       "      <td>250</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.017730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAQ_R_df</td>\n",
       "      <td>712</td>\n",
       "      <td>498</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.967290</td>\n",
       "      <td>0.976636</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.976636</td>\n",
       "      <td>0.973131</td>\n",
       "      <td>0.004474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCL5_df</td>\n",
       "      <td>402</td>\n",
       "      <td>281</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.824380</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PHQ9_GAD7_df</td>\n",
       "      <td>1118</td>\n",
       "      <td>782</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PID5_df</td>\n",
       "      <td>824</td>\n",
       "      <td>576</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRFQ_df</td>\n",
       "      <td>678</td>\n",
       "      <td>474</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.004902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRMQ_df</td>\n",
       "      <td>1404</td>\n",
       "      <td>982</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0.907583</td>\n",
       "      <td>0.888626</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.895142</td>\n",
       "      <td>0.009937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RAW_DDDT</td>\n",
       "      <td>986</td>\n",
       "      <td>690</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.746622</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.006757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R_NEO_PI</td>\n",
       "      <td>77687</td>\n",
       "      <td>54380</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>0.906938</td>\n",
       "      <td>0.907067</td>\n",
       "      <td>0.915004</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>0.913417</td>\n",
       "      <td>0.911840</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sPID-5_df</td>\n",
       "      <td>1038</td>\n",
       "      <td>726</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965545</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset name  Sample size  Training size  Number of Features  \\\n",
       "0      BF_df_CTU          442            309                  10   \n",
       "1       BF_df_OU          460            322                  10   \n",
       "2        BF_df_V          486            340                  10   \n",
       "3       DT_df_CC          482            337                  27   \n",
       "4       DT_df_JI          864            604                  27   \n",
       "5        IADQ_df          450            315                   9   \n",
       "6        IESR_df          358            250                  22   \n",
       "7       NAQ_R_df          712            498                  22   \n",
       "8        PCL5_df          402            281                  20   \n",
       "9   PHQ9_GAD7_df         1118            782                  16   \n",
       "10       PID5_df          824            576                 220   \n",
       "11       PRFQ_df          678            474                  18   \n",
       "12       PRMQ_df         1404            982                  16   \n",
       "13      RAW_DDDT          986            690                  12   \n",
       "14      R_NEO_PI        77687          54380                  30   \n",
       "15     sPID-5_df         1038            726                  25   \n",
       "\n",
       "    Selected Features  ACCURACY - Logit with all features  \\\n",
       "0                   4                            0.774436   \n",
       "1                   4                            0.833333   \n",
       "2                   2                            0.760274   \n",
       "3                   5                            0.682759   \n",
       "4                   4                            0.661538   \n",
       "5                   3                            0.851852   \n",
       "6                   4                            0.935185   \n",
       "7                   6                            0.953271   \n",
       "8                   2                            0.809917   \n",
       "9                   3                            0.991071   \n",
       "10                  1                            0.959677   \n",
       "11                  5                            0.936275   \n",
       "12                  6                            0.907583   \n",
       "13                  6                            0.746622   \n",
       "14                 18                            0.906938   \n",
       "15                  6                            0.961538   \n",
       "\n",
       "    ACCURACY - Logistic Regression  ACCURACY - SVM  ACCURACY - Random Forest  \\\n",
       "0                         0.812030        0.842105                  0.827068   \n",
       "1                         0.797101        0.847826                  0.840580   \n",
       "2                         0.719178        0.719178                  0.726027   \n",
       "3                         0.717241        0.717241                  0.731034   \n",
       "4                         0.646154        0.584615                  0.592308   \n",
       "5                         0.851852        0.837037                  0.837037   \n",
       "6                         0.888889        0.925926                  0.907407   \n",
       "7                         0.967290        0.976636                  0.971963   \n",
       "8                         0.826446        0.826446                  0.818182   \n",
       "9                         0.979167        0.982143                  0.976190   \n",
       "10                        0.891129        0.891129                  0.891129   \n",
       "11                        0.931373        0.931373                  0.921569   \n",
       "12                        0.888626        0.909953                  0.890995   \n",
       "13                        0.743243        0.756757                  0.756757   \n",
       "14                        0.907067        0.915004                  0.911872   \n",
       "15                        0.967949        0.967949                  0.964744   \n",
       "\n",
       "    ACCURACY - Neural Network  Average Accuracy on selected features  \\\n",
       "0                    0.812030                               0.823308   \n",
       "1                    0.833333                               0.829710   \n",
       "2                    0.719178                               0.720890   \n",
       "3                    0.703448                               0.717241   \n",
       "4                    0.638462                               0.615385   \n",
       "5                    0.844444                               0.842593   \n",
       "6                    0.925926                               0.912037   \n",
       "7                    0.976636                               0.973131   \n",
       "8                    0.826446                               0.824380   \n",
       "9                    0.979167                               0.979167   \n",
       "10                   0.891129                               0.891129   \n",
       "11                   0.931373                               0.928922   \n",
       "12                   0.890995                               0.895142   \n",
       "13                   0.756757                               0.753378   \n",
       "14                   0.913417                               0.911840   \n",
       "15                   0.961538                               0.965545   \n",
       "\n",
       "    Accuracy std on selected features  \n",
       "0                            0.014397  \n",
       "1                            0.022530  \n",
       "2                            0.003425  \n",
       "3                            0.011262  \n",
       "4                            0.031404  \n",
       "5                            0.007092  \n",
       "6                            0.017730  \n",
       "7                            0.004474  \n",
       "8                            0.004132  \n",
       "9                            0.002430  \n",
       "10                           0.000000  \n",
       "11                           0.004902  \n",
       "12                           0.009937  \n",
       "13                           0.006757  \n",
       "14                           0.003429  \n",
       "15                           0.003069  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = []\n",
    "for k, v in data_collection.items():\n",
    "    \n",
    "    # Dataset name\n",
    "    # Sample size\n",
    "    # Training size\n",
    "    # Initial number of features\n",
    "    # Selected features\n",
    "    # ACCURACY: Full Logit\n",
    "    # ACCURACY: Logistic Regression\n",
    "    # ACCURACY: SVC\n",
    "    # ACCURACY: Random Forest\n",
    "    # ACCURACY: Neural Network\n",
    "    # Average accuracy (full logit excluded)\n",
    "    # Accuracy Standard deviation (full logit excluded)\n",
    "    \n",
    "    summary += [[k, len(v[2]) + len(v[3]), len(v[2]),\n",
    "                 v[0].shape[1], len(v[4][\"Features\"]),\n",
    "                 *v[5].tolist(), v[5][1:].mean(), v[5][1:].std()]]\n",
    "    \n",
    "summary = pd.DataFrame(summary,\n",
    "                       columns = [\"Dataset name\", \"Sample size\", \"Training size\", \"Number of Features\",\n",
    "                                  \"Selected Features\", \"ACCURACY - Logit with all features\",\n",
    "                                  \"ACCURACY - Logistic Regression\", \"ACCURACY - SVM\", \"ACCURACY - Random Forest\",\n",
    "                                  \"ACCURACY - Neural Network\", \"Average Accuracy on selected features\",\n",
    "                                  \"Accuracy std on selected features\"])\n",
    "\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
