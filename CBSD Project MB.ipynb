{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65e68df",
   "metadata": {},
   "source": [
    "# Cognitive, behavioral and social data\n",
    "**Author**: Mattia Brocco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46adef96",
   "metadata": {},
   "source": [
    "MERGE OF DATASETS FOR **R_NEO_PI**\n",
    "```python\n",
    "a = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Faked.xlsx\")\n",
    "b = pd.read_excel(data_dir + \"\\\\R_NEO_PI_Honest.xlsx\")\n",
    "\n",
    "a.columns = [\" \".join([pd.Series(a.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       a.loc[0][i]]) for i in range(len(a.columns))]\n",
    "b.columns = [\" \".join([pd.Series(b.columns).apply(lambda s: np.nan if \"Unnamed\"\n",
    "                                                  in s else s).fillna(method = \"ffill\").tolist()[i],\n",
    "                       b.loc[0][i]]) for i in range(len(b.columns))]\n",
    "\n",
    "a = a.drop(0).reset_index(drop = True)\n",
    "b = b.drop(0).reset_index(drop = True)\n",
    "\n",
    "a[\"CONDITION\"] = \"FAKE\"\n",
    "b[\"CONDITION\"] = \"HONEST\"\n",
    "\n",
    "pd.concat([a, b], ignore_index = True).to_excel(data_dir + \"\\\\R_NEO_PI.xlsx\", index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6cda3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T14:26:53.220836Z",
     "start_time": "2022-11-25T14:26:25.192592Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import support\n",
    "import evaluation\n",
    "from engine import Classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = \".\\\\data\"\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb0745",
   "metadata": {},
   "source": [
    "### Datasets at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0038cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T14:26:54.658155Z",
     "start_time": "2022-11-25T14:26:53.224712Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BF_df_CTU.parquet</td>\n",
       "      <td>442</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BF_df_OU.parquet</td>\n",
       "      <td>460</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BF_df_V.parquet</td>\n",
       "      <td>486</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_df_CC.parquet</td>\n",
       "      <td>482</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT_df_JI.parquet</td>\n",
       "      <td>864</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IADQ_df.parquet</td>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IESR_df.parquet</td>\n",
       "      <td>358</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAQ_R_df.parquet</td>\n",
       "      <td>712</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCL5_df.parquet</td>\n",
       "      <td>402</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PHQ9_GAD7_df.parquet</td>\n",
       "      <td>1118</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PID5_df.parquet</td>\n",
       "      <td>824</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRFQ_df.parquet</td>\n",
       "      <td>678</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRMQ_df.parquet</td>\n",
       "      <td>1404</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RAW_DDDT.parquet</td>\n",
       "      <td>986</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R_NEO_PI.parquet</td>\n",
       "      <td>77687</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sPID-5_df.parquet</td>\n",
       "      <td>1038</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Data  Sample size  Features\n",
       "0      BF_df_CTU.parquet          442        11\n",
       "1       BF_df_OU.parquet          460        11\n",
       "2        BF_df_V.parquet          486        11\n",
       "3       DT_df_CC.parquet          482        28\n",
       "4       DT_df_JI.parquet          864        28\n",
       "5        IADQ_df.parquet          450        10\n",
       "6        IESR_df.parquet          358        23\n",
       "7       NAQ_R_df.parquet          712        23\n",
       "8        PCL5_df.parquet          402        21\n",
       "9   PHQ9_GAD7_df.parquet         1118        17\n",
       "10       PID5_df.parquet          824       221\n",
       "11       PRFQ_df.parquet          678        19\n",
       "12       PRMQ_df.parquet         1404        17\n",
       "13      RAW_DDDT.parquet          986        13\n",
       "14      R_NEO_PI.parquet        77687        31\n",
       "15     sPID-5_df.parquet         1038        26"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_descr = pd.DataFrame(dict(zip([f for f in os.listdir(data_dir) if \"parquet\" in f],\n",
    "                                   [pd.read_parquet(f\"{data_dir}\\\\{f}\").shape for f in os.listdir(data_dir)\n",
    "                                    if \"parquet\" in f]))).T.reset_index()\n",
    "data_descr = data_descr.rename(columns = {\"index\": \"Data\", 0: \"Sample size\",\n",
    "                                          1: \"Features\"})\n",
    "data_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f32564",
   "metadata": {},
   "source": [
    "## Design a pipeline\n",
    "***\n",
    "\n",
    "The goal is to find a stable subset of features across datasets that performs roughly the same across different classifiers. Accoringly, we can define a \"good\" feature selection procedure, one that does not depend on a specific model, but that allows models to perform roughly the same, and for all the datasets within the scope.\n",
    "\n",
    "##### DESCRIPTION\n",
    "1. A given dataset is split in training and test. For every feature, the mean and the standard deviation are computed in order to scale that feauture: $Z=\\frac{X-\\mu}{\\sigma}$. Scaling on the test set is carried out using the same values computed for training data.\n",
    "2. The actual phase of the selection of a subset of features occurs through a 3-step process:  \n",
    "    * Train a Decision Tree and apply minimal cost-complexity pruning. <sup>[1]</sup>  \n",
    "    * Train a Random Forest that expolits gradient boosting <sup>[2]</sup>, in which each tree retains the cost-complexity parameter obtained in the previous step.  \n",
    "    * Compute permutation importance on this Random Forest <sup>[3]</sup>.  \n",
    "    * Perform a one-sample test on the mean, given the distribution obtained for each feature importance (with confidence level at 99.999%). This way only features whose importance is significantly greater than zero are retained, all the others are discarded. We call this subset of feature $A^*$  \n",
    "    * Perform a Wilks test <sup>[4]</sup> comparing two logistic regressions, one fitted with the full set of features, the other with $A^*$. By accepting the null hypothesis of the test (at 95% confidence level), the assertion \"the ration  between the likelihoods of the two (nested) models is one\".  \n",
    "    * Train an arbitrary amount of different models in order to assess the quality of the feature selection procedure. If all models show very close accuracy, then the procedure proves to provide a model-indifferent subset $A^*$ of features.\n",
    "\n",
    "\n",
    "##### SOURCES\n",
    "* [How can I get statistics to compare nested models in a logistic regression in SPSS?](https://www.ibm.com/support/pages/how-can-i-get-statistics-compare-nested-models-logistic-regression-spss)\n",
    "* [Likelihood-ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test)\n",
    "\n",
    "##### SUPPORTING PAPERS\n",
    "[1] L. Breiman, J. Friedman, R. Olshen, and C. Stone. *Classification and Regression Trees*. Wadsworth, Belmont, CA, 1984.  \n",
    "[2] J. Friedman, Greedy Function Approximation: *A Gradient Boosting Machine*, The Annals of Statistics, Vol. 29, No. 5, 2001  \n",
    "[3] Leo Breiman. Random forests. *Machine learning*, 45(1):5-32, 2001.  \n",
    "[4] Li, Bing; Babu, G. Jogesh (2019). *A Graduate Course on Statistical Inference*. Springer. p. 331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb893e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-25T14:26:37.665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF_df_CTU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf73640bf65a4bde8dc038c03b877b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Train size: 309\n",
      "Selected 4 features out of 10\n",
      "{'Features': [2, 4, 6, 7], 'Wilks test p-value': 0.9893064, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4\n",
      "Full Logit           0.774436   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.812030   6.0   2.0   4.0   7.0\n",
      "SVC                  0.842105   6.0   2.0   4.0   7.0\n",
      "Random Forest        0.827068   6.0   7.0   2.0   4.0\n",
      "Neural Network       0.812030   4.0   7.0   6.0   2.0\n",
      "\n",
      "==> STABILITY SCORE: 0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "BF_df_OU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2d6d2c6d6040d983366cba2d914a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Train size: 322\n",
      "Selected 3 features out of 10\n",
      "{'Features': [4, 6, 7], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3\n",
      "Full Logit           0.833333   NaN   NaN   NaN\n",
      "Logistic Regression  0.811594   6.0   4.0   7.0\n",
      "SVC                  0.818841   6.0   4.0   7.0\n",
      "Random Forest        0.782609   6.0   4.0   7.0\n",
      "Neural Network       0.818841   6.0   4.0   7.0\n",
      "\n",
      "==> STABILITY SCORE: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "BF_df_V\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92150352d8c450082e2644aedfbab44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Train size: 340\n",
      "Selected 1 features out of 10\n",
      "{'Features': [7], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1\n",
      "Full Logit           0.760274   NaN\n",
      "Logistic Regression  0.684932   7.0\n",
      "SVC                  0.684932   7.0\n",
      "Random Forest        0.684932   7.0\n",
      "Neural Network       0.684932   7.0\n",
      "\n",
      "==> STABILITY SCORE: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DT_df_CC\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5956ecb5e7ed4e5091bdc67f62e9754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Train size: 337\n",
      "Selected 3 features out of 27\n",
      "{'Features': [9, 10, 13], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3\n",
      "Full Logit           0.682759   NaN   NaN   NaN\n",
      "Logistic Regression  0.731034  13.0  10.0   9.0\n",
      "SVC                  0.724138  13.0  10.0   9.0\n",
      "Random Forest        0.710345  13.0  10.0   9.0\n",
      "Neural Network       0.744828  13.0   9.0  10.0\n",
      "\n",
      "==> STABILITY SCORE: 0.778\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "DT_df_JI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b752864575476f838fa74dc96d39a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "Train size: 604\n",
      "Selected 5 features out of 27\n",
      "{'Features': [2, 3, 6, 15, 18], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4  FI 5\n",
      "Full Logit           0.661538   NaN   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.653846   2.0  18.0   6.0  15.0   3.0\n",
      "SVC                  0.630769  15.0  18.0   2.0   6.0   3.0\n",
      "Random Forest        0.607692  18.0  15.0   6.0   2.0   3.0\n",
      "Neural Network       0.657692  18.0   6.0   2.0  15.0   3.0\n",
      "\n",
      "==> STABILITY SCORE: 0.533\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "IADQ_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82543e397a294f66895af37e801e1228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Train size: 315\n",
      "Selected 2 features out of 9\n",
      "{'Features': [4, 6], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2\n",
      "Full Logit           0.851852   NaN   NaN\n",
      "Logistic Regression  0.829630   6.0   4.0\n",
      "SVC                  0.822222   4.0   6.0\n",
      "Random Forest        0.814815   4.0   6.0\n",
      "Neural Network       0.822222   4.0   6.0\n",
      "\n",
      "==> STABILITY SCORE: 0.667\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "IESR_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fd1f76c3cf45b09729045b2a5b9d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Train size: 250\n",
      "Selected 4 features out of 22\n",
      "{'Features': [8, 13, 18, 19], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4\n",
      "Full Logit           0.935185   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.888889   8.0  18.0  19.0  13.0\n",
      "SVC                  0.925926  13.0   8.0  18.0  19.0\n",
      "Random Forest        0.907407  18.0  13.0   8.0  19.0\n",
      "Neural Network       0.925926  13.0  19.0  18.0   8.0\n",
      "\n",
      "==> STABILITY SCORE: 0.25\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "NAQ_R_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a12a457c0e4c2c9156e057bc2aa21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "Train size: 498\n",
      "Selected 1 features out of 22\n",
      "{'Features': [9], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "                     Accuracy  FI 1\n",
      "Full Logit           0.953271   NaN\n",
      "Logistic Regression  0.929907   9.0\n",
      "SVC                  0.929907   9.0\n",
      "Random Forest        0.929907   9.0\n",
      "Neural Network       0.929907   9.0\n",
      "\n",
      "==> STABILITY SCORE: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "PCL5_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a92a2b5465433b8c05690a39e08f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Train size: 281\n",
      "Selected 2 features out of 20\n",
      "{'Features': [1, 4], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2\n",
      "Full Logit           0.809917   NaN   NaN\n",
      "Logistic Regression  0.826446   4.0   1.0\n",
      "SVC                  0.826446   1.0   4.0\n",
      "Random Forest        0.818182   1.0   4.0\n",
      "Neural Network       0.826446   4.0   1.0\n",
      "\n",
      "==> STABILITY SCORE: 0.667\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "PHQ9_GAD7_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c861915ada5a4cc8ac3f445e12d90f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "Train size: 782\n",
      "Selected 4 features out of 16\n",
      "{'Features': [0, 1, 6, 7], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4\n",
      "Full Logit           0.991071   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.982143   7.0   1.0   6.0   0.0\n",
      "SVC                  0.982143   7.0   1.0   6.0   0.0\n",
      "Random Forest        0.973214   7.0   1.0   6.0   0.0\n",
      "Neural Network       0.982143   7.0   1.0   6.0   0.0\n",
      "\n",
      "==> STABILITY SCORE: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "PID5_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed7dc7b7993431d975e6dbd7d5a9e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "Train size: 576\n",
      "Selected 3 features out of 220\n",
      "{'Features': [1, 53, 191], 'Wilks test p-value': 1.0, 'High correlation': True}\n",
      "                     Accuracy  FI 1   FI 2   FI 3\n",
      "Full Logit           0.959677   NaN    NaN    NaN\n",
      "Logistic Regression  0.927419   1.0  191.0   53.0\n",
      "SVC                  0.939516   1.0  191.0   53.0\n",
      "Random Forest        0.923387   1.0  191.0   53.0\n",
      "Neural Network       0.931452   1.0   53.0  191.0\n",
      "\n",
      "==> STABILITY SCORE: 0.778\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "PRFQ_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35714b8626bc4076b5a72b2459441a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "Train size: 474\n",
      "Selected 4 features out of 18\n",
      "{'Features': [6, 7, 8, 11], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4\n",
      "Full Logit           0.936275   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.892157  11.0   6.0   7.0   8.0\n",
      "SVC                  0.882353   8.0  11.0   6.0   7.0\n",
      "Random Forest        0.916667   6.0  11.0   7.0   8.0\n",
      "Neural Network       0.901961  11.0   8.0   7.0   6.0\n",
      "\n",
      "==> STABILITY SCORE: 0.417\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "PRMQ_df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4870229bd74d3386e1a632872d05ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "Train size: 982\n",
      "Selected 5 features out of 16\n",
      "{'Features': [1, 4, 7, 12, 14], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4  FI 5\n",
      "Full Logit           0.907583   NaN   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.890995   1.0  12.0   7.0   4.0  14.0\n",
      "SVC                  0.912322   1.0   7.0  12.0   4.0  14.0\n",
      "Random Forest        0.888626   1.0   7.0  12.0   4.0  14.0\n",
      "Neural Network       0.893365   1.0   7.0  12.0   4.0  14.0\n",
      "\n",
      "==> STABILITY SCORE: 0.867\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "RAW_DDDT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe5efeeada74ce49bbfcf694ceb4d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "Train size: 690\n",
      "Selected 4 features out of 12\n",
      "{'Features': [0, 1, 9, 10], 'Wilks test p-value': 1.0, 'High correlation': False}\n",
      "                     Accuracy  FI 1  FI 2  FI 3  FI 4\n",
      "Full Logit           0.746622   NaN   NaN   NaN   NaN\n",
      "Logistic Regression  0.746622   1.0  10.0   9.0   0.0\n",
      "SVC                  0.766892  10.0   1.0   0.0   9.0\n",
      "Random Forest        0.760135  10.0   1.0   0.0   9.0\n",
      "Neural Network       0.750000   1.0  10.0   0.0   9.0\n",
      "\n",
      "==> STABILITY SCORE: 0.667\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "R_NEO_PI\n"
     ]
    }
   ],
   "source": [
    "### PIPELINE\n",
    "# Organize datasets\n",
    "data_collection = {}\n",
    "for dataset in [f for f in os.listdir(data_dir) if \"parquet\" in f]:\n",
    "    print(dataset.split(\".\")[0])\n",
    "    X_tr, X_ts, y_tr, y_ts = Classification().prepare_data(f\"{data_dir}\\\\{dataset}\", \"CONDITION\")\n",
    "    var_sel = Classification().variable_selection(X_tr, X_ts, y_tr, y_ts)\n",
    "    perfs, stability = Classification().benchmark_models(X_tr, X_ts, y_tr, y_ts, var_sel)\n",
    "    data_collection[dataset.split(\".\")[0]] = [X_tr, X_ts, y_tr, y_ts, var_sel, perfs, stability]\n",
    "    print(var_sel)\n",
    "    print(perfs)\n",
    "    print()\n",
    "    print(\"==> STABILITY SCORE: {}\".format(stability))\n",
    "    print(\"-\" * 100)\n",
    "    print(\"-\" * 100)\n",
    "    print(\"-\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e026d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T10:43:57.660751Z",
     "start_time": "2022-11-21T10:43:57.429876Z"
    }
   },
   "source": [
    "## Assess quality of analysis\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee78dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T19:38:05.668230Z",
     "start_time": "2022-11-24T19:37:56.675994Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare with correlation matrices\n",
    "# The greener the higher the correlation\n",
    "f0, ax0 = plt.subplots(4, 4, figsize = (20, 24))\n",
    "for n, k in enumerate(data_collection.keys()):\n",
    "    \n",
    "    sns.heatmap(pd.DataFrame(data_collection[k][0]).corr().abs(),\n",
    "                vmin = 0, vmax = 1, cmap = \"YlGn\",\n",
    "                cbar = False, ax = ax0[n//4, n%4])\n",
    "    ax0[n//4, n%4].set_title(\"{} - {} selected\"\\\n",
    "                             .format(k, len(data_collection[k][-3][\"Features\"])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1baa89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T19:38:11.705900Z",
     "start_time": "2022-11-24T19:38:05.671242Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrices of only selected features\n",
    "# The greener the higher the correlation\n",
    "f1, ax1 = plt.subplots(4, 4, figsize = (20, 24))\n",
    "for n, k in enumerate(data_collection.keys()):\n",
    "    \n",
    "    feats = data_collection[k][-2][\"Features\"]\n",
    "    \n",
    "    annotation = True if len(feats) < 7 else False\n",
    "    \n",
    "    sns.heatmap(pd.DataFrame(data_collection[k][0][:,feats]).corr().abs(),\n",
    "                vmin = 0, vmax = 1, cmap = \"YlGn\", annot = annotation,\n",
    "                cbar = False, ax = ax1[n//4, n%4])\n",
    "\n",
    "    ax1[n//4, n%4].set_title(k)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce20af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T19:40:15.027911Z",
     "start_time": "2022-11-24T19:39:31.009686Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "benchmark = evaluation.lasso_benchmark(data_collection)\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark,\n",
    "                            columns = [\"Dataset\", \"Algo\", \"λ min\", \"λ 1se\",\n",
    "                                       \"Zero coeffs at λ min\",\n",
    "                                       \"Delta accuracy\"]).drop(\"Algo\", axis = 1)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45610b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-24T19:53:04.846707Z",
     "start_time": "2022-11-24T19:53:04.624064Z"
    }
   },
   "outputs": [],
   "source": [
    "#evaluation.graphical_lasso_benchmark(benchmark[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1745d9a",
   "metadata": {},
   "source": [
    "## Summarize results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac3cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T22:39:03.448891Z",
     "start_time": "2022-11-22T22:39:03.020981Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "for k, v in data_collection.items():\n",
    "    \n",
    "    # Dataset name\n",
    "    # Sample size\n",
    "    # Training size\n",
    "    # Initial number of features\n",
    "    # Selected features\n",
    "    # Stability\n",
    "    # ACCURACY: Full Logit\n",
    "    # ACCURACY: Logistic Regression\n",
    "    # ACCURACY: SVC\n",
    "    # ACCURACY: Random Forest\n",
    "    # ACCURACY: Neural Network\n",
    "    # Average accuracy (full logit excluded)\n",
    "    # Accuracy Standard deviation (full logit excluded)\n",
    "    # Decreased accuracy (mean) w.r.t. full logit\n",
    "    \n",
    "    summary += [[k, len(v[2]) + len(v[3]), len(v[2]),\n",
    "                 v[0].shape[1], len(v[4][\"Features\"]),\n",
    "                 v[6], *v[5].tolist(), v[5][1:].mean(),\n",
    "                 v[5][1:].std(), v[5][1:].mean() - v[5].tolist()[0]]]\n",
    "    \n",
    "summary = pd.DataFrame(summary,\n",
    "                       columns = [\"Dataset name\", \"Sample size\", \"Training size\", \"Number of Features\",\n",
    "                                  \"Selected Features\", \"Feat. Stability\", \"Accuracy - Logit all features\",\n",
    "                                  \"Accuracy - Logit\", \"Accuracy - SVM\", \"Accuracy - RF\",\n",
    "                                  \"Accuracy - MLP\", \"Avg Acc. on selected features\",\n",
    "                                  \"Accuracy Std on selected features\", \"Acc. diff. wrt Full logit\"])\n",
    "\n",
    "summary = summary.applymap(lambda v: v if isinstance(v, str) else round(v, 3))\n",
    "\n",
    "summary.sort_values(\"Accuracy Std on selected features\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f4620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T22:39:04.188973Z",
     "start_time": "2022-11-22T22:39:03.451030Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 7))\n",
    "plt.bar(x = summary.sort_values(\"Avg Acc. on selected features\",\n",
    "                                ascending = False)[\"Dataset name\"],\n",
    "        height = summary.sort_values(\"Avg Acc. on selected features\",\n",
    "                                     ascending = False)[\"Avg Acc. on selected features\"],\n",
    "        yerr = summary.sort_values(\"Avg Acc. on selected features\",\n",
    "                                   ascending = False)[\"Accuracy Std on selected features\"], alpha = .7)\n",
    "plt.xticks(rotation = 35, fontsize = 13)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel(\"Accuracy\\n(mean ± std)\", fontsize = 13, rotation = 0, labelpad = 50)\n",
    "plt.title(\"Accuracy on different datasets\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51477df2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T22:39:04.823045Z",
     "start_time": "2022-11-22T22:39:04.191898Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 6))\n",
    "plt.bar(x = summary.sort_values(\"Accuracy Std on selected features\",\n",
    "                                ascending = False)[\"Dataset name\"],\n",
    "        height = summary.sort_values(\"Accuracy Std on selected features\",\n",
    "                                     ascending = False)[\"Accuracy Std on selected features\"], alpha = .7)\n",
    "plt.xticks(rotation = 35, fontsize = 13)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel(\"Stand. Dev.\", fontsize = 13, rotation = 0, labelpad = 30)\n",
    "plt.title(\"Standard Deviation of Accuracies on different datasets\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0594f98",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
